{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This project uses the dataset from [The Chars74K dataset](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label class mapping\n",
    "classMap = list()\n",
    "# Add 0-9\n",
    "for i in range(10):\n",
    "    classMap.append(str(i))\n",
    "# Add A-Z\n",
    "for i in range(65, 91):\n",
    "    classMap.append(chr(i))\n",
    "# Add a-z\n",
    "for i in range(97, 123):\n",
    "    classMap.append(chr(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataSet(Dataset):\n",
    "    def __init__(self, dataPath, transform=None):\n",
    "        self.dataPath = dataPath\n",
    "        # Get all subdirectories in dataPath\n",
    "        subdirNames = os.listdir(dataPath)\n",
    "        subdirNames.sort()\n",
    "        # Get the number of files in each subdirectory\n",
    "        self.imgs = list()\n",
    "        self.labels = list()\n",
    "        for i in range(len(subdirNames)):\n",
    "            subdirName = subdirNames[i]\n",
    "            # Get the path of the subdirectory\n",
    "            subdirPath = os.path.join(dataPath, subdirName)\n",
    "            # Read all files in the subdirectory\n",
    "            files = os.listdir(subdirPath)\n",
    "            # Get file path\n",
    "            for file in files:\n",
    "                filePath = os.path.join(subdirPath, file)\n",
    "                # Read image and label\n",
    "                img = image.imread(filePath)\n",
    "                # If image is grayscale, convert to RGB\n",
    "                if len(img.shape) == 2:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                \n",
    "                # Transform image\n",
    "                if transform is not None:\n",
    "                    img = transform(img)\n",
    "                # Get label\n",
    "                label = i\n",
    "                # Convert to tensor\n",
    "                label = torch.tensor(label)\n",
    "                # Add to list\n",
    "                self.imgs.append(img)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Check range\n",
    "        if index < 0 or index >= len(self):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        # Get image and label\n",
    "        img = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Sum all the files in each subdirectory\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transform\n",
    "class ImageTransform():\n",
    "    def __init__(self, size, normalize=True, toTensor=True):\n",
    "        self.size = size\n",
    "        self.normalize = normalize\n",
    "        self.toTensor = toTensor\n",
    "\n",
    "    def __call__(self, img: np.ndarray):\n",
    "        # Resize image\n",
    "        img = cv2.resize(img, self.size)\n",
    "        # Normalize image by deviding by max value in image\n",
    "        if self.normalize:\n",
    "            img = img / np.amax(img)\n",
    "        # Convert to tensor\n",
    "        if self.toTensor:\n",
    "            img = torch.from_numpy(np.array(img))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_SET_PATH = os.path.join(\n",
    "#     \"data\",\"EnglishImg\",\"English\",\"Img\",\"GoodImg\",\"Bmp\"\n",
    "# )\n",
    "# DATA_SET_PATH = os.path.join(\n",
    "# #     \"data\",\"EnglishFnt\",\"English\",\"Fnt\"\n",
    "# #      \"F:\",\"SIG\",\"English-CNN-OCR-main\",\"English\",\"Img\",\"GoodImg\",\"Bmp\"\n",
    "#         \"EnglishFnt\",\"English\",\"Fnt\"\n",
    "# )\n",
    "\n",
    "DATA_SET_PATH = '../English-CNN-OCR-main/English1/Fnt/'\n",
    "charDataSet = CharDataSet(dataPath=DATA_SET_PATH, transform=ImageTransform(size=(32, 32)))\n",
    "dataLoader = DataLoader(charDataSet, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 16 images\n",
    "charDataIter = iter(dataLoader)\n",
    "# fig, ax = plt.subplots(4, 4)\n",
    "# for i in range(16):\n",
    "#     img, label = next(charDataIter)\n",
    "#     ax[i // 4, i % 4].imshow(img.squeeze().numpy(), cmap=\"gray\")\n",
    "#     ax[i // 4, i % 4].set_title(classMap[label[0]])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAccuracy(model, testLoader, testSetSize = -1):\n",
    "    \"\"\"\n",
    "    Get the accuracy of the model on the test set.\n",
    "    Set the testSetSize to -1 to use the entire test set.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (imgs, labels) in enumerate(testLoader):\n",
    "            # Break when reach test set size\n",
    "            if testSetSize >= 0 and i >= testSetSize:\n",
    "                break\n",
    "\n",
    "            # Reshape images to (batch_size, 3, 32, 32)\n",
    "            imgs = imgs.view(-1, 3, 32, 32)\n",
    "            imgs = imgs.to(device)\n",
    "            # Forward pass\n",
    "            out = model(imgs)\n",
    "            # Get the index of the max log-probability\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            # Move predicted to cpu\n",
    "            predicted = predicted.cpu() \n",
    "            # Compute the number of correct predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSetSize = int(len(charDataSet) * 0.8)\n",
    "trainingDataSet, testingDataSet = torch.utils.data.random_split(\n",
    "    charDataSet, [trainingSetSize, len(charDataSet) - trainingSetSize], generator=torch.Generator().manual_seed(0)\n",
    ")\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainingDataSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = DataLoader(dataset=testingDataSet, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CharClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharClassifier, self).__init__()\n",
    "        # Input size: (3, 32, 32)\n",
    "        # Convolutional layer 1: (3, 32, 32) -> (16, 30, 30)\n",
    "#         self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.conv1 = nn.Conv2d(3, 15, 3)\n",
    "        \n",
    "        # Pooling layer 1: (16, 30, 30) -> (16, 15, 15)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Convolutional layer 2: (16, 15, 15) -> (32, 13, 13)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(15, 32, 3)\n",
    "        \n",
    "        # Pooling layer 2: (32, 13, 13) -> (32, 6, 6)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layer: (32*conv16) -> (256)\n",
    "#         self.fc1 = nn.Linear(32*6*6, 256)\n",
    "        self.fc1 = nn.Linear(32*6*6, 256)\n",
    "        # Hidden layer: (256) -> (128)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # Output layer: (64) -> (size of classMap)\n",
    "        self.fc3 = nn.Linear(128, len(classMap))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(-1, 32*6*6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the model\n",
    "model = CharClassifier()\n",
    "# Move the model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [787/3150], Loss: 4.1241\n",
      "Epoch [1/10], Step [1574/3150], Loss: 4.1021\n",
      "Epoch [1/10], Step [2361/3150], Loss: 4.0769\n",
      "Epoch [1/10], Step [3148/3150], Loss: 2.7643\n",
      "Epoch [1/10], Test Accuracy: 19.70%\n",
      "Epoch [2/10], Step [787/3150], Loss: 2.0055\n",
      "Epoch [2/10], Step [1574/3150], Loss: 1.9306\n",
      "Epoch [2/10], Step [2361/3150], Loss: 1.1601\n",
      "Epoch [2/10], Step [3148/3150], Loss: 1.3614\n",
      "Epoch [2/10], Test Accuracy: 63.22%\n",
      "Epoch [3/10], Step [787/3150], Loss: 0.3748\n",
      "Epoch [3/10], Step [1574/3150], Loss: 1.8075\n",
      "Epoch [3/10], Step [2361/3150], Loss: 1.1755\n",
      "Epoch [3/10], Step [3148/3150], Loss: 0.7417\n",
      "Epoch [3/10], Test Accuracy: 72.23%\n",
      "Epoch [4/10], Step [787/3150], Loss: 1.2230\n",
      "Epoch [4/10], Step [1574/3150], Loss: 0.8980\n",
      "Epoch [4/10], Step [2361/3150], Loss: 0.9922\n",
      "Epoch [4/10], Step [3148/3150], Loss: 0.4387\n",
      "Epoch [4/10], Test Accuracy: 75.57%\n",
      "Epoch [5/10], Step [787/3150], Loss: 0.6717\n",
      "Epoch [5/10], Step [1574/3150], Loss: 0.5554\n",
      "Epoch [5/10], Step [2361/3150], Loss: 1.5246\n",
      "Epoch [5/10], Step [3148/3150], Loss: 0.8805\n",
      "Epoch [5/10], Test Accuracy: 77.47%\n",
      "Epoch [6/10], Step [787/3150], Loss: 1.3590\n",
      "Epoch [6/10], Step [1574/3150], Loss: 0.3510\n",
      "Epoch [6/10], Step [2361/3150], Loss: 0.3311\n",
      "Epoch [6/10], Step [3148/3150], Loss: 0.3031\n",
      "Epoch [6/10], Test Accuracy: 78.78%\n",
      "Epoch [7/10], Step [787/3150], Loss: 0.7956\n",
      "Epoch [7/10], Step [1574/3150], Loss: 0.7566\n",
      "Epoch [7/10], Step [2361/3150], Loss: 0.5520\n",
      "Epoch [7/10], Step [3148/3150], Loss: 0.9364\n",
      "Epoch [7/10], Test Accuracy: 78.15%\n",
      "Epoch [8/10], Step [787/3150], Loss: 0.8976\n",
      "Epoch [8/10], Step [1574/3150], Loss: 0.7576\n",
      "Epoch [8/10], Step [2361/3150], Loss: 0.7588\n",
      "Epoch [8/10], Step [3148/3150], Loss: 0.4242\n",
      "Epoch [8/10], Test Accuracy: 79.71%\n",
      "Epoch [9/10], Step [787/3150], Loss: 0.2485\n",
      "Epoch [9/10], Step [1574/3150], Loss: 0.1319\n",
      "Epoch [9/10], Step [2361/3150], Loss: 0.0742\n",
      "Epoch [9/10], Step [3148/3150], Loss: 0.5682\n",
      "Epoch [9/10], Test Accuracy: 81.13%\n",
      "Epoch [10/10], Step [787/3150], Loss: 0.0869\n",
      "Epoch [10/10], Step [1574/3150], Loss: 0.3807\n",
      "Epoch [10/10], Step [2361/3150], Loss: 0.3473\n",
      "Epoch [10/10], Step [3148/3150], Loss: 0.3828\n",
      "Epoch [10/10], Test Accuracy: 82.01%\n"
     ]
    }
   ],
   "source": [
    "stepNum = len(trainLoader)\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (imgs, labels) in enumerate(trainLoader):\n",
    "        # Reshape images to (batch_size, 3, 32, 32)\n",
    "        imgs = imgs.view(-1, 3, 32, 32)\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(imgs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = lossFunc(out, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss\n",
    "        if (i + 1) % (stepNum // 4) == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(epoch + 1, EPOCH, i + 1, stepNum, loss.item()))\n",
    "    # Get accuracy on test set\n",
    "    accuracy = GetAccuracy(model, testLoader)\n",
    "    print(\"Epoch [{}/{}], Test Accuracy: {:.2f}%\".format(epoch + 1, EPOCH, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 82.43%\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy on the test set\n",
    "accuracy = GetAccuracy(model, testLoader)\n",
    "print(\"Test set accuracy: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3165289e1b956da4608a3d9be55cd0c9633c4657a6d18128fbadef8815fb10f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
